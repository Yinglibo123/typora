# langchain

## 介绍

**LangChain** 是一个基于语言模型开发应用程序的框架。它可以实现以下功能：

- 数据感知：将语言模型与其他数据源连接起来
- 主动性：允许语言模型与其环境交互

### 模块

- 模块输入/输出：与语言模型进行接口交互
- 数据连接：与特定于应用程序的数据进行接口交互
- 链式组装：构造调用序列
- 代理：根据高级指令让链式组装选择要使用的工具
- 内存：在链式组装的多次运行之间持久化应用程序状态
- 回调：记录和流式传输任何链式组装的中间步骤

### 安装

安装langchain： pip install langchain 

使用 LangChain 通常需要与一个或多个模型提供者、数据存储、API 等集成。在此示例中，我们将使用 OpenAI 的模型 API。pip install openai

export OPENAI_API_KEY="..."       设置环境变量

### LLMs

使用语言模型获取预测的结果。

from langchain.llms import OpenAI

llm = OpenAI(openai_api_key="...",temperature=0.9)      不设置环境变量

使用较高的温度来初始化可以获得更随机的结果

llm.predict("问题")



### 聊天模型

聊天模型是语言模型的一种变体。虽然聊天模型在内部使用语言模型，但其公开的接口略有不同：它们不是提供“文本输入，文本输出”的 API，而是提供了一个“聊天消息”作为输入和输出的接口。

Langchain支持的消息类型：==AIMessage，HumanMessage，SystemMessage==，ChatMessage（接受任意角色参数），大多数情况下，只需处理前三种、

例子：

```python
from langchain.chat_models import ChatOpenAI
from langchain.schema import(
    AIMessage,
    HumanMessage,
    SystemMessage
)
chat=ChatOpenAI(temperature=0,openai_api_key="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")
chat.predict_messages([HumanMessage(content="1+1等于多少")])
#chat.predict("1+1等于多少")
```

### 提示模版

大多数 LLM 应用程序不会直接将用户输入传递给 LLM。通常，它们会==将用户输入添加到一个更大的文本片段中，称为提示模板==，在特定任务上==提供额外的上下文==。

#### LLMs

例子：

```python
from langchain.prompts import PromptTemplate
prompt=PromptTemplate.from_template("{东西}是什么颜色？")
prompt.format(东西="天空")
# '天空是什么颜色？'
```

#### 聊天模型

```python
from langchain.prompts.chat import(
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
template="You are a assistant that translates {input_language} to {output_language}"
system_message_template=SystemMessagePromptTemplate.from_template(template)
human_template="{text}"
human_message_prompt=HumanMessagePromptTemplate.from_template(human_template)
chat_prompt=ChatPromptTemplate.from_messages([system_message_template,human_message_prompt])
chat_prompt.format_messages(input_language="English",output_language="Chinese",text="I love music")

输出：[SystemMessage(content='You are a assistant that translates English to Chinese', additional_kwargs={}),
 HumanMessage(content='I love music', additional_kwargs={}, example=False)]
```



### 链

链提供了一种将多个原语（如模型、提示和其他链）链接（或链）在一起的方法。



### 代理

代理使用语言模型来确定要采取的动作及其顺序。代理可以访问工具，并反复选择工具、运行工具并观察输出，直到得出最终答案。

要加载一个代理，需要：

- LLM/Chat模型
- 工具：执行特定任务的函数。比如：Google搜索，数据库查找，Python REPL，其他链等
- 代理名称：一个字符串



### 内存

链和代理都是无状态的，但对于许多应用程序来说，引用过去的交互是必要的。

聊天模型与LLMs的内存不同之处在于：将它们保留为自己（system,human,ai）独特的内存对象，而不是尝试将所有先前的消息压缩成一个字符串



# 微信文章

RAG：检索搜索生成,Retrieval Augmented Generation

LLM的问题：

- 幻视问题：大模型的底层原理是基于概率，所以它有时候会一本正经胡说八道，在很多需要非常精确的场景，仅仅依赖GPT的这种生成式回答是很不严谨的，而且看很难消除——目前常见的解决方案是前置一个BERT，或者预置大量prompt做优化。
- 新鲜度问题：规模越大（参数越多、tokens越多），大模型训练的成本越高。类似OpenAI的ChatGPT3.5，目前的数据新鲜度依然保留在2021年，对于之后的事情就不知道了。
- 数据安全：既要保证安全，又要借助AI能力，那么最好的方式就是把数据全部放在本地，企业数据的业务计算全部在本地完成。而在线的大模型仅仅完成一个归纳的功能，甚至，LLM都可以完全本地化部署。
- tokens的限制

**RAG架构：（索引，检索，生成）**

数据提取——embedding（向量化）——创建索引——检索——自动排序（Rerank）——LLM归纳生成。当然这里少了使用环节，我们暂时先忽略用户提问的环节。

![19b9b2272b5687c30fa4196cba00a677](./image/19b9b2272b5687c30fa4196cba00a677.png)